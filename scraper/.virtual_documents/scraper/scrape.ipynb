from bs4 import BeautifulSoup
import requests
import pandas as pd



intern_url='https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=python&location=Ireland&geoId=104738515&trk=public_jobs_jobs-search-bar_search-submit&start=25'
list_url='https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Computer%2BScience%2B&location=Ireland&geoId=104738515&trk=public_jobs_jobs-search-bar_search-submit&start=25'

response=requests.get(list_url)
list_data=response.text
list_soup=BeautifulSoup(list_data,"html.parser")
page_jobs=list_soup.find_all('li')
#print(page_jobs)


id_list=[]
for job in page_jobs:
    base_card_div = job.find("div",class_="base-card")
    job_id=base_card_div.get("data-entity-urn").split(":")[3]
    #print(job_id)
    id_list.append(job_id)
    print(id_list)
    





intern_url='https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=python&location=Ireland&geoId=104738515&trk=public_jobs_jobs-search-bar_search-submit&start=25'
list_url='https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Computer%2BScience%2B&location=Ireland&geoId=104738515&trk=public_jobs_jobs-search-bar_search-submit&start=25'

response=requests.get(list_url)
list_data=response.text
list_soup=BeautifulSoup(list_data,"html.parser")
page_jobs=list_soup.find_all('li')
#print(page_jobs)


jobs_fetched=0
total_jobs=25
while jobs_fetched<total_jobs:
    id_list=[]
    for job in page_jobs:
        base_card_div = job.find("div",class_="base-card")
        job_id=base_card_div.get("data-entity-urn").split(":")[3]
        #print(job_id)
        id_list.append(job_id)
       # print(id_list)
        
    jobs_available=[]
    
    for job_id in id_list:
        intern_url2=f'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}'
        list_url=f'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}'
        r=requests.get(list_url)
        list_data2=r.text
        job_post={}
        job_info=BeautifulSoup(list_data2,"html.parser")
        
        comp_name=job_info.find('a',class_='topcard__org-name-link topcard__flavor--black-link')
        
        comp = comp_name.text.strip() if comp_name else "Company name not found"
        job_post["Job_name"] = comp
        applicant_info = job_info.find('div', class_='top-card-layout__entity-info-container')
    
        num_applicants_element = applicant_info.find('span', class_='num-applicants__caption')
        num_applicants = num_applicants_element.text.strip() if num_applicants_element else "Number of applicants not found"
        job_post["Number of applicants"] = num_applicants 
    
        time_element=applicant_info.find('span',class_="posted-time-ago__text")
        time=time_element.text.strip() if time_element else "Date posted not found"
        job_post["Date posted"] = time
        
        location_element = applicant_info.find('span', class_='topcard__flavor topcard__flavor--bullet')
        loc = location_element.text.strip()
        job_post["Location"] = loc
        
        role_element=applicant_info.find('h2',class_='top-card-layout__title')
        role=role_element.text.strip()
        job_post["Job title"] = role
        
        print(f"Company name: {comp}")
        print(f"Role: {role}")
        print(f"Location: {loc}")
        print(f"Posted {time} ago")
        print(f"Number of applicants: {num_applicants}")
        print("        ")
        jobs_available.append(job_post)
        jobs_fetched+=1
    start=len(id_list)
print(jobs_available)





import requests
from bs4 import BeautifulSoup

base_url = 'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search'
keywords = 'Computer+Science'
location = 'Ireland'
geo_id = '104738515'
total_jobs_to_fetch = 25  # Total number of jobs to fetch

start = 0
jobs_fetched = 0
jobs_available = []

while jobs_fetched < total_jobs_to_fetch:
    url = f'{base_url}?keywords={keywords}&location={location}&geoId={geo_id}&trk=public_jobs_jobs-search-bar_search-submit&start={start}'
    response = requests.get(url)
    
    if response.status_code == 200:
        list_soup = BeautifulSoup(response.text, "html.parser")
        page_jobs = list_soup.find_all('li')

        id_list = []
        for job in page_jobs:
            base_card_div = job.find("div", class_="base-card")
            if base_card_div:
                job_id = base_card_div.get("data-entity-urn").split(":")[3]
                id_list.append(job_id)

        # Fetch details for each job ID
        for job_id in id_list:
            job_url = f'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}'
            r = requests.get(job_url)
            
            if r.status_code == 200:
                job_info = BeautifulSoup(r.text, "html.parser")
                
                # Initialize dictionary for job post
                job_post = {}
                
                # Extract company name
                comp_name = job_info.find('a', class_='topcard__org-name-link topcard__flavor--black-link')
                comp = comp_name.text.strip() if comp_name else "Company name not found"
                job_post["Company name"] = comp
                
                # Extract role
                role_element = job_info.find('h2', class_='top-card-layout__title')
                role = role_element.text.strip() if role_element else "Role not found"
                job_post["Job title"] = role
                
                # Extract location
                location_element = job_info.find('span', class_='topcard__flavor topcard__flavor--bullet')
                loc = location_element.text.strip() if location_element else "Location not found"
                job_post["Location"] = loc
                
                # Extract posted time
                time_element = job_info.find('span', class_='posted-time-ago__text')
                time = time_element.text.strip() if time_element else "Date posted not found"
                job_post["Date posted"] = time
                
                # Extract number of applicants
                applicant_info = job_info.find('div', class_='top-card-layout__entity-info-container')
                num_applicants_element = applicant_info.find('span', class_='num-applicants__caption')
                num_applicants = num_applicants_element.text.strip() if num_applicants_element else "Number of applicants not found"
                job_post["Number of applicants"] = num_applicants
                
                # Print job details
                print(f"Company name: {comp}")
                print(f"Role: {role}")
                print(f"Location: {loc}")
                print(f"Posted {time} ago")
                print(f"Number of applicants: {num_applicants}")
                print()  # Empty line for separation
                
                jobs_available.append(job_post)
                jobs_fetched += 1  # Increment job count

                if jobs_fetched >= total_jobs_to_fetch:
                    break  # Exit inner loop if desired number of jobs is reached

            else:
                print(f"Failed to fetch job details for job ID: {job_id}")
            
        if jobs_fetched >= total_jobs_to_fetch:
            break  # Exit outer loop if desired number of jobs is reached
        
        start += len(id_list)  # Move to the next page of results

    else:
        print(f"Failed to fetch job listings. Status code: {response.status_code}")
        break  # Exit loop if request fails

print(jobs_available)
















